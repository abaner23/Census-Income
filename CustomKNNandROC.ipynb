{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name- Arnab Banerjee\n",
    "## Course No- CSE 5243\n",
    "### Lab No- Lab2(K-NN)\n",
    "### Date- 20/02/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import sklearn.metrics as met\n",
    "\n",
    "#This function takes two education levels as input and produces their mapped output as per the following rules:\n",
    "#Education- ordinal variable\n",
    "        #1-8 education level- 1\n",
    "        #9-12 education level- 2\n",
    "        #13- 6\n",
    "        #14-15- 12\n",
    "        #16- 24\n",
    "def MapWithOrdinal(val1,val2):\n",
    "    out1=0\n",
    "    out2=0\n",
    "    if(val1>=1 and val1<=8):\n",
    "       out1=1\n",
    "    elif(val1>=9 and val1<=12):\n",
    "       out1=2\n",
    "    elif(val1==13):\n",
    "        out1=6\n",
    "    elif(val1==14 or val1==15):\n",
    "        out1=12\n",
    "    elif(val1==16):\n",
    "        out1=24\n",
    "        \n",
    "    if(val2>=1 and val2<=8):\n",
    "       out2=1\n",
    "    elif(val2>=9 and val2<=12):\n",
    "       out2=2\n",
    "    elif(val2==13):\n",
    "        out2=6\n",
    "    elif(val2==14 or val2==15):\n",
    "        out2=12\n",
    "    elif(val2==16):\n",
    "        out2=24\n",
    "    return [out1,out2]\n",
    "def CustomDissimilarityFunction(A,B,nominal,ordinal,continuous,variances):\n",
    "    #This function returns the dissimilarity between two data rows A and B.\n",
    "    # It also accepts array of nominal, ordinal, continuous features as parameters and accepts variances of continuous\n",
    "    #variables to be used for normalization\n",
    "    #Relationship, Education deleted\n",
    "    #Gender- Male or female If A[gender]=B[gender] then 0 othewise 1\n",
    "    #Native- Countries If A[country]=B[country] then 0 otherwise 1\n",
    "    #Marital Status same, Race same\n",
    "    #Age = |A[age]-B[age]|/Variance(age). Same definition for hours per week,capital gain and capital loss, finalwgt\n",
    "\n",
    "    \n",
    "    d_nominal=0\n",
    "    d_ordinal=0\n",
    "    d_conti=0\n",
    "    for i in range(0,nominal.shape[0]):\n",
    "        if(A[nominal[i]]!=B[nominal[i]]):\n",
    "            d_nominal=d_nominal+1\n",
    "    for i in range(0,ordinal.shape[0]):\n",
    "        [mapped_A, mapped_B]=MapWithOrdinal(A[ordinal[i]],B[ordinal[i]])\n",
    "        d_ordinal=d_ordinal+abs((mapped_A-mapped_B)/(24-1))\n",
    "    for i in range(0,continuous.shape[0]):\n",
    "        d_conti=d_conti+(abs(A[continuous[i]]-B[continuous[i]])/mt.sqrt(variances[i]))\n",
    "    return d_nominal+d_ordinal+d_conti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row # 0 Closest Rows= [347 349 284  70 270] DissimilarityValues=[ 1.17614351  1.39126227  1.42221993  1.44755337  1.6188541 ]\n",
      "Row # 1 Closest Rows= [191 436 344  46  70] DissimilarityValues=[ 1.27269137  1.42726108  1.51026036  1.81288758  1.943822  ]\n",
      "Row # 2 Closest Rows= [353 247 320  42 440] DissimilarityValues=[ 3.35275796  3.42630141  3.4363825   3.44324051  3.44549468]\n",
      "Row # 3 Closest Rows= [454 503 302  35 189] DissimilarityValues=[ 4.23248898  4.49375926  4.63478744  4.74842693  4.82588608]\n"
     ]
    }
   ],
   "source": [
    "def PrintKNearestNeighbors(k=5):\n",
    "    \n",
    "    trainset=pd.read_csv(\"C:\\\\Users\\\\barna\\\\Downloads\\\\income_tr.csv\")\n",
    "    trainset_copy=trainset\n",
    "    trainset.drop(['ID','education','relationship','class'],axis=1,inplace=True)\n",
    "    cols = trainset.columns\n",
    "    continuous_variables= np.array(trainset._get_numeric_data().columns)\n",
    "    nominal_variables=np.array(list(set(cols) - set(continuous_variables)))\n",
    "    ordinal_variables=np.array([cols[3]])\n",
    "    continuous_variables=np.delete(continuous_variables,[2])\n",
    "    variances=np.empty(continuous_variables.shape[0],dtype=float)\n",
    "    \n",
    "    for i in range(0,continuous_variables.shape[0]):\n",
    "        variances[i]=np.var(np.array(trainset[continuous_variables[i]]))\n",
    "        \n",
    "    DissimilarityIndex=np.empty([trainset_copy.shape[0],trainset_copy.shape[0]],dtype=float)\n",
    "    for i in range(0,trainset_copy.shape[0]):\n",
    "        for j in range(0, trainset_copy.shape[0]):\n",
    "            DissimilarityIndex[i,j]=-1\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        for j in range(0, trainset_copy.shape[0]):\n",
    "            if(i!=j and DissimilarityIndex[i,j]==-1):\n",
    "                DissimilarityIndex[i,j]=CustomDissimilarityFunction(trainset.iloc[i,:],trainset.iloc[j,:],nominal_variables,ordinal_variables,continuous_variables,variances)\n",
    "        closest_indexes=np.array(DissimilarityIndex[i,:].argsort()[:k+1],dtype=int)\n",
    "     \n",
    "        \n",
    "        print('Row # {} Closest Rows= {} DissimilarityValues={}'.format(i,closest_indexes[1:],np.reshape(DissimilarityIndex[i,[closest_indexes[1:]]],k)))\n",
    "        \n",
    "       # The below part of code if uncommented will save all the output_part1.csv file which is attached along with the submission\n",
    "        #x=np.reshape(closest_indexes[1:],(1,k))\n",
    "        #y=np.reshape(DissimilarityIndex[i,[closest_indexes[1:]]],(1,k))\n",
    "        #t=np.reshape(np.array(i),(1,1))\n",
    "        #z=np.concatenate((t,x,y),axis=1)\n",
    "        #df = pd.DataFrame(z)\n",
    "        #df.to_csv('C:\\\\Users\\\\barna\\\\Downloads\\\\output_part1.csv',mode='a',header=False,index=False)\n",
    "        \n",
    "PrintKNearestNeighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Actual Class Predicted Class Posterior Probability P(Y=1|X)\n",
      "0     0            0                0.2\n",
      "1     0            0                0.2\n",
      "2     1            0                0.2\n",
      "3     0            0                0.0\n",
      "4     0            0                0.0\n",
      "5     0            0                0.0\n",
      "6     0            0                0.0\n",
      "7     0            0                0.4\n",
      "8     1            1                1.0\n",
      "9     1            1                0.8\n",
      "Confustion Matrix=\n",
      "[[7 0]\n",
      " [1 2]]\n",
      "Accuracy=0.9\n",
      "Error rate=0.09999999999999998\n",
      "True Negative=7\n",
      "True Positive=2\n",
      "False Positive=0\n",
      "False Negative=1\n",
      "Precision=1.0\n",
      "Recall=0.6666666666666666\n",
      "F-score=0.8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tocat(h):\n",
    "    #print(type(h))\n",
    "    if(h==' >50K'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def PrintKNearestNeighbors(filelocation,k=5,threshold=0.5):\n",
    "    \n",
    "    trainset=pd.read_csv(\"C:\\\\Users\\\\barna\\\\Downloads\\\\income_tr.csv\")\n",
    "    trainset['class'] = trainset['class'].apply(tocat)\n",
    "    testset=pd.read_csv(filelocation)\n",
    "    testset['class'] = testset['class'].apply(tocat)\n",
    "    testset_classes=testset.iloc[:,15]\n",
    "    trainset_classes=trainset.iloc[:,15]\n",
    "    testset.drop(['ID','education','relationship','class'],axis=1,inplace=True)\n",
    "    trainset.drop(['ID','education','relationship','class'],axis=1,inplace=True)\n",
    "    cols = testset.columns\n",
    "    continuous_variables= np.array(testset._get_numeric_data().columns)\n",
    "    nominal_variables=np.array(list(set(cols) - set(continuous_variables)))\n",
    "    ordinal_variables=np.array([cols[3]])\n",
    "    continuous_variables=np.delete(continuous_variables,[2])\n",
    "    variances=np.empty(continuous_variables.shape[0],dtype=float)\n",
    "    \n",
    "    for i in range(0,continuous_variables.shape[0]):\n",
    "        variances[i]=np.var(np.array(trainset[continuous_variables[i]]))\n",
    "        \n",
    "    DissimilarityIndex=np.empty([testset.shape[0],trainset.shape[0]],dtype=float)\n",
    "    for i in range(0,testset.shape[0]):\n",
    "        for j in range(0, trainset.shape[0]):\n",
    "            DissimilarityIndex[i,j]=-1\n",
    "    \n",
    "    range1=10\n",
    "    predicted_classes=np.empty(range1,dtype=int)\n",
    "    print(\"{} {} {} {}\".format('Index','Actual Class','Predicted Class','Posterior Probability P(Y=1|X)'))\n",
    "    for i in range(0,range1):\n",
    "        for j in range(0, trainset.shape[0]):\n",
    "            if(i!=j and DissimilarityIndex[i,j]==-1):\n",
    "                DissimilarityIndex[i,j]=CustomDissimilarityFunction(testset.iloc[i,:],trainset.iloc[j,:],nominal_variables,ordinal_variables,continuous_variables,variances)\n",
    "        closest_indexes=np.array(DissimilarityIndex[i,:].argsort()[:k+1],dtype=int)\n",
    "        classes_closest=np.array(trainset_classes[closest_indexes[1:]])\n",
    "        \n",
    "        number_classes1=np.sum(classes_closest)\n",
    "       \n",
    "        number_classes0=k-number_classes1\n",
    "        if((number_classes1/k)>=threshold):\n",
    "            predicted_class=1\n",
    "            posterior=number_classes1/k\n",
    "        else:\n",
    "            predicted_class=0\n",
    "            posterior=number_classes1/k\n",
    "        predicted_classes[i]=predicted_class\n",
    "        print(\"{}     {}            {}                {}\".format(i,testset_classes[i],predicted_class,posterior))\n",
    "\n",
    "    #This section gives the model performance\n",
    "    \n",
    "    confusion_m=met.confusion_matrix(testset_classes[0:range1],predicted_classes)\n",
    "    print(\"Confustion Matrix=\")\n",
    "    print(confusion_m)\n",
    "    print(\"Accuracy={}\".format((confusion_m[0,0]+confusion_m[1,1])/range1))\n",
    "    print(\"Error rate={}\".format(1.0-(confusion_m[0,0]+confusion_m[1,1])/range1))\n",
    "    print(\"True Negative={}\".format(confusion_m[0,0]))\n",
    "    print(\"True Positive={}\".format(confusion_m[1][1]))\n",
    "    print(\"False Positive={}\".format(confusion_m[0][1]))\n",
    "    print(\"False Negative={}\".format(confusion_m[1][0]))\n",
    "    print(\"Precision={}\".format(confusion_m[1][1]/(confusion_m[1][1]+confusion_m[0][1])))\n",
    "    print(\"Recall={}\".format(confusion_m[1][1]/(confusion_m[1][1]+confusion_m[1][0])))\n",
    "    print(\"F-score={}\".format((2*confusion_m[1][1])/((confusion_m[1][1]+confusion_m[0][1])+(confusion_m[1][1]+confusion_m[1][0]))))\n",
    "\n",
    "def KnnOnTestDataset(filelocation,k=5,threshold=0.5):\n",
    "    \n",
    "    if(k%2==0):\n",
    "        print('Please pass an odd value of k')\n",
    "    else:\n",
    "        PrintKNearestNeighbors(filelocation,k,threshold)\n",
    "            \n",
    "    return\n",
    "\n",
    "KnnOnTestDataset(\"C:\\\\Users\\\\barna\\\\Downloads\\\\income_te.csv\",5,0.62)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation of Approach\n",
    "\n",
    "1. Partitioned the set of features into continuous, ordinal and nominal features which was used as parameters to CustomDissimilarityFunction so that the function is as general as possible.\n",
    "2. I have used Dissimilarity as the proximity measure. Thus I have used the k least dissimilar points to find the k closest points.\n",
    "3. I have considered Education Level as an ordinal variable with non-equal distances between two levels. The mapping which I have used is specified in the function definition of MapWithOrdinal as comments.\n",
    "4. Within CustomDissimilarityFunction function, I have used the following measures for computing dissimilarity between row A and B.\n",
    "\n",
    "  ### if x is a nominal variable\n",
    "  if A[x]=B[x] then\n",
    "     Dissimilarity=0\n",
    "   else\n",
    "      Dissimilarity=1\n",
    "   ### if x is an ordinal variable\n",
    "   |MappedValue of A[x]- MappedValue of B[x]|/(MaxValue- MinValue)\n",
    "   \n",
    "   ### if x is a continuous variable\n",
    "   |A[x]-B[x]|/StandardDeviation(x)\n",
    "   \n",
    "   Here we are dividing the value by Sample Standard Deviation so as to normalize the numerator. Here one assumption is x follows a Gaussian Distribution. We can use other normalization techniques but I follow the above. \n",
    "    \n",
    "5. K-Nearest Neighbour model does not explicitly require any kind of training. For each new row of test data, I calculated the K least dissimilar points and then predicted the class of the test data row by checking posterior probabilities of respective class given the test data and used the threshold to make final prediction. Since the test data set income_te.csv contained the true outputs I calculated the accuracy by using the proportion of correct predictions. In addition Confusion Matrix and other model performance metrics like Precision, Recall and F-Score is also shown. \n",
    "6. I am also restricting the use of even values of k so that we can avoid the situation in which we cannot find out the majority class. Of course this situation arises specially for the default threshold value of 0.5.\n",
    "7. I assume including ID feature is not appropriate for calculating Dissimilarity. Also Education feature is redundant to Education_Level and Relationship feature is redundant to Marital Status. Thus I removed Education and Relationship from the analysis.\n",
    "8. Changing the class <=50K to 0 and >50k to 1 helped in calculating the posterior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Keeping the threshold t=0.5 we find the test performance for k=3,5,7,9,11,13 and it shows that the model's accuracy hovers around 78-79% and does not change much. The best performance comes at k=9 with accuracy of 79.86% while k values lower than that produces accuracy below that(78%-79.5%) and also k values larger than 9 produces accuracy below that(77-78%). The model with k=9 also acheives highest precision of 66%.\n",
    "\n",
    "Here is a detailed comparison of the performance measures across all k values:\n",
    "\n",
    "1. K=3\n",
    "Accuracy=0.7847222222222222\n",
    "Error rate=0.2152777777777778\n",
    "True Negative=199\n",
    "True Positive=27\n",
    "False Positive=22\n",
    "False Negative=40\n",
    "Precision=0.5510204081632653\n",
    "Recall=0.40298507462686567\n",
    "F-score=0.46551724137931033\n",
    "\n",
    "2. K=5\n",
    "Accuracy=0.7847222222222222\n",
    "Error rate=0.2152777777777778\n",
    "True Negative=203\n",
    "True Positive=23\n",
    "False Positive=18\n",
    "False Negative=44\n",
    "Precision=0.5609756097560976\n",
    "Recall=0.34328358208955223\n",
    "F-score=0.42592592592592593\n",
    "\n",
    "3. K=7\n",
    "Accuracy=0.7951388888888888\n",
    "Error rate=0.20486111111111116\n",
    "True Negative=207\n",
    "True Positive=22\n",
    "False Positive=14\n",
    "False Negative=45\n",
    "Precision=0.6111111111111112\n",
    "Recall=0.3283582089552239\n",
    "F-score=0.42718446601941745\n",
    "\n",
    "4. K=9\n",
    "\n",
    "Accuracy=0.7986111111111112\n",
    "Error rate=0.20138888888888884\n",
    "True Negative=212\n",
    "True Positive=18\n",
    "False Positive=9\n",
    "False Negative=49\n",
    "Precision=0.6666666666666666\n",
    "Recall=0.26865671641791045\n",
    "F-score=0.3829787234042553\n",
    "\n",
    "5. K=11\n",
    "\n",
    "Accuracy=0.7847222222222222\n",
    "Error rate=0.2152777777777778\n",
    "True Negative=211\n",
    "True Positive=15\n",
    "False Positive=10\n",
    "False Negative=52\n",
    "Precision=0.6\n",
    "Recall=0.22388059701492538\n",
    "F-score=0.32608695652173914\n",
    "\n",
    "6. K=13\n",
    "\n",
    "Accuracy=0.7743055555555556\n",
    "Error rate=0.22569444444444442\n",
    "True Negative=209\n",
    "True Positive=14\n",
    "False Positive=12\n",
    "False Negative=53\n",
    "Precision=0.5384615384615384\n",
    "Recall=0.208955223880597\n",
    "F-score=0.3010752688172043\n",
    "\n",
    "The above performance results show that there is not much difference between performance values for different values of k. That shows that taking only few ~5 closest observations will be very representative of those who will be correctly classified by our model. Since the performance does not increase with more value of k it shows that taking more observations does not benefit us and better is keeping the value of k so that the computation times is lesser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can see from the CustomDissimilarityFunction definition that we accept a list of nominal, ordinal and continous attributes. Thus, this function can be used for any dataset given we know which features fall in which category. We need to accept the list of ordinal variables from the user as there is no way to understand whether a feature is ordinal beforehand. To find the list of continuous variables I have used the function trainset._get_numeric_data().columns. To find the list of nominal variables we find the set difference of the set of features and set of numeric features. Thus after finding these lists we can pass those to CustomDissimilarityFunction definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code generates the ROC curve for the above model using only 30 instances so as to reduce the computational time. Changing the value of range1 will change the number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ea8cd18d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Feb  6 12:44:25 2018\n",
    "\n",
    "@author: barna\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import sklearn.metrics as met\n",
    "import matplotlib.pyplot as plt\n",
    "def MapWithOrdinal(val1,val2):\n",
    "    out1=0\n",
    "    out2=0\n",
    "    if(val1>=1 and val1<=8):\n",
    "       out1=1\n",
    "    elif(val1>=9 and val1<=12):\n",
    "       out1=2\n",
    "    elif(val1==13):\n",
    "        out1=6\n",
    "    elif(val1==14 or val1==15):\n",
    "        out1=12\n",
    "    elif(val1==16):\n",
    "        out1=24\n",
    "        \n",
    "    if(val2>=1 and val2<=8):\n",
    "       out2=1\n",
    "    elif(val2>=9 and val2<=12):\n",
    "       out2=2\n",
    "    elif(val2==13):\n",
    "        out2=6\n",
    "    elif(val2==14 or val2==15):\n",
    "        out2=12\n",
    "    elif(val2==16):\n",
    "        out2=24\n",
    "    return [out1,out2]\n",
    "def CustomDissimilarityFunction(A,B,nominal,ordinal,continuous,variances):\n",
    "    #Relationship, Education deleted\n",
    "    #Gender- Male or female If A[gender]=B[gender] then 0 othewise 1\n",
    "    #Native- Countries If A[country]=B[country] then 0 otherwise 1\n",
    "    #Marital Status same, Race same\n",
    "    #Age = |A[age]-B[age]| hours per week same capital gain and capital loss same, finalwgt same\n",
    "    #Education- ordinal variable\n",
    "        #1-8 education level- 1\n",
    "        #9-12 education level- 2\n",
    "        #13- 6\n",
    "        #14-15- 12\n",
    "        #16- 24\n",
    "    d_nominal=0\n",
    "    d_ordinal=0\n",
    "    d_conti=0\n",
    "    for i in range(0,nominal.shape[0]):\n",
    "        if(A[nominal[i]]!=B[nominal[i]]):\n",
    "            d_nominal=d_nominal+1\n",
    "    for i in range(0,ordinal.shape[0]):\n",
    "        [mapped_A, mapped_B]=MapWithOrdinal(A[ordinal[i]],B[ordinal[i]])\n",
    "        d_ordinal=d_ordinal+abs((mapped_A-mapped_B)/(24-1))\n",
    "    for i in range(0,continuous.shape[0]):\n",
    "        d_conti=d_conti+(abs(A[continuous[i]]-B[continuous[i]])/mt.sqrt(variances[i]))\n",
    "    return d_nominal+d_ordinal+d_conti\n",
    "\n",
    "def tocat(h):\n",
    "    #print(type(h))\n",
    "    if(h==' >50K'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def DrawROC(threshold_values):\n",
    "    print(threshold_values.shape[0])\n",
    "    x=np.empty(threshold_values.shape[0]+1,dtype=float)\n",
    "    y=np.empty(threshold_values.shape[0]+1,dtype=float)\n",
    "    for i in range(0,threshold_values.shape[0]):\n",
    "        [tpr,fpr,o1]=KnnOnTestDataset(\"C:\\\\Users\\\\barna\\\\Downloads\\\\income_te.csv\",5,threshold_values[threshold_values.shape[0]-i-1])\n",
    "        x[i]=fpr\n",
    "        y[i]=tpr\n",
    "    x[threshold_values.shape[0]]=1\n",
    "    y[threshold_values.shape[0]]=1\n",
    "    plt.plot(x,y,linewidth=2)\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylim((0,1))\n",
    "    plt.xlim((0,1))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def PrintKNearestNeighbors(filelocation,k=5,threshold=0.5):\n",
    "    \n",
    "    trainset=pd.read_csv(\"C:\\\\Users\\\\barna\\\\Downloads\\\\income_tr.csv\")\n",
    "    trainset['class'] = trainset['class'].apply(tocat)\n",
    "    testset=pd.read_csv(filelocation)\n",
    "    testset['class'] = testset['class'].apply(tocat)\n",
    "    testset_classes=testset.iloc[:,15]\n",
    "    trainset_classes=trainset.iloc[:,15]\n",
    "    testset.drop(['ID','education','relationship','class'],axis=1,inplace=True)\n",
    "    trainset.drop(['ID','education','relationship','class'],axis=1,inplace=True)\n",
    "    cols = testset.columns\n",
    "    continuous_variables= np.array(testset._get_numeric_data().columns)\n",
    "    nominal_variables=np.array(list(set(cols) - set(continuous_variables)))\n",
    "    ordinal_variables=np.array([cols[3]])\n",
    "    continuous_variables=np.delete(continuous_variables,[2])\n",
    "    variances=np.empty(continuous_variables.shape[0],dtype=float)\n",
    "    \n",
    "    for i in range(0,continuous_variables.shape[0]):\n",
    "        variances[i]=np.var(np.array(trainset[continuous_variables[i]]))\n",
    "        \n",
    "    DissimilarityIndex=np.empty([testset.shape[0],trainset.shape[0]],dtype=float)\n",
    "    for i in range(0,testset.shape[0]):\n",
    "        for j in range(0, trainset.shape[0]):\n",
    "            DissimilarityIndex[i,j]=-1\n",
    "    \n",
    "    range1=30\n",
    "    predicted_classes=np.empty(range1,dtype=int)\n",
    "    posterior_probs=np.empty(range1,dtype=float)\n",
    "    for i in range(0,range1):\n",
    "        for j in range(0, trainset.shape[0]):\n",
    "            if(i!=j and DissimilarityIndex[i,j]==-1):\n",
    "                DissimilarityIndex[i,j]=CustomDissimilarityFunction(testset.iloc[i,:],trainset.iloc[j,:],nominal_variables,ordinal_variables,continuous_variables,variances)\n",
    "        closest_indexes=np.array(DissimilarityIndex[i,:].argsort()[:k+1],dtype=int)\n",
    "        classes_closest=np.array(trainset_classes[closest_indexes[1:]])\n",
    "        \n",
    "        number_classes1=np.sum(classes_closest)\n",
    "       \n",
    "        \n",
    "        if((number_classes1/k)>threshold):\n",
    "            predicted_class=1\n",
    "            posterior=number_classes1/k\n",
    "        else:\n",
    "            predicted_class=0\n",
    "            posterior=number_classes1/k\n",
    "        predicted_classes[i]=predicted_class\n",
    "        posterior_probs[i]=posterior\n",
    "\n",
    "    \n",
    "    confusion_m=met.confusion_matrix(testset_classes[0:range1],predicted_classes)\n",
    "    return[confusion_m[1][1]/(confusion_m[1][1]+confusion_m[1][0]),confusion_m[0][1]/(confusion_m[0][1]+confusion_m[0,0]),np.unique(posterior_probs)]\n",
    "    \n",
    "\n",
    "def KnnOnTestDataset(filelocation,k=5,threshold=0.5):\n",
    "    \n",
    "    if(k%2==0):\n",
    "        print('Please pass an odd value of k')\n",
    "    else:\n",
    "        [a,b,c]=PrintKNearestNeighbors(filelocation,k,threshold)\n",
    "            \n",
    "    return[a,b,c]\n",
    "    \n",
    "[a,b,posterior_probs]=KnnOnTestDataset(\"C:\\\\Users\\\\barna\\\\Downloads\\\\income_te.csv\",5,0.5)\n",
    "\n",
    "DrawROC(np.unique(posterior_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
